import json
from typing import Dict, Any


class CaseAgent:
    """
    An agent responsible for retrieving historical soccer precedents and comparing them
    to the current scenario to determine factual relevance.
    """

    def __init__(self, cases_collection: Any, client: Any):
        """
        Initializes the CaseAgent.

        Args:
            cases_collection: The ChromaDB collection containing historical cases.
            client: The OpenAI client instance for LLM interactions.
        """
        self.cases_collection = cases_collection
        self.client = client

    def search(self, query_text: str) -> Dict[str, Any]:
        """
        Retrieves historical cases based on the query text and analyzes their relevance using an LLM.

        Args:
            query_text (str): The raw text for text-based questions, or the action description
                              generated by VideoAgent for video-based questions.

        Returns:
            Dict[str, Any]: A dictionary containing the relevance judgment, explanation,
                            historical verdict, and key differences.
        """
        print(f"   [CaseAgent] Searching similar cases for: {query_text[:50]}...")

        top_cases_text = []

        # --- 1. RAG Retrieval ---
        try:
            # Retrieve only the top 1 most relevant case
            results = self.cases_collection.query(
                query_texts=[query_text],
                n_results=1
            )

            # Extract document content safely
            if results.get('documents') and len(results['documents']) > 0:
                # ChromaDB returns a list of lists (one list per query)
                top_cases_text = results['documents'][0]
            else:
                top_cases_text = ["No similar cases found."]

        except Exception as e:
            print(f"   [CaseAgent] DB Error: {e}")
            return {
                "is_relevant": False,
                "similarity_explanation": f"Database Error: {str(e)}",
                "historical_answer": "None",
                "key_difference": "N/A"
            }

        # --- 2. Format Retrieval Results ---
        # Format the retrieved text for the LLM prompt
        cases_str = "\n".join([f"Historical Case {i + 1}: {c}" for i, c in enumerate(top_cases_text)])

        # --- 3. LLM Analysis & Comparison ---
        system_prompt = (
            "You are a specialized Legal Analyst for Soccer Precedents. "
            "Your ONLY job is to determine if a retrieved historical case is FACTUALLY comparable to the current scenario. "
            "Be extremely skeptical. If the content is different, reject the case."
        )

        # NOTE: Fixed a bug where 'top_cases_text' (list) was used instead of 'cases_str' (string)
        user_prompt = (
            f"=== CURRENT SCENARIO ===\n\"{query_text}\"\n\n"
            f"=== RETRIEVED HISTORICAL CASE ===\n\"{cases_str}\"\n\n"
            f"### INSTRUCTIONS ###\n"
            f"1. **Relevance Check**:\n"
            f"   - Does the **physical mechanism** match?\n"
            f"   - Does the **specific topic** match? \n\n"
            f"2. **Output Logic**:\n"
            f"   - If the topics/mechanisms do not match, set 'is_relevant' to False.\n"
            f"   - If they match, extract the answer/verdict.\n\n"
            f"### OUTPUT FORMAT (JSON ONLY) ###\n"
            f"Return a JSON object:\n"
            f"- 'is_relevant': boolean (True only if offense type AND mechanism match substantially)\n"
            f"- 'similarity_explanation': Why it matches or why it fails.\n"
            f"- 'historical_answer': The decision made in the historical case (if mentioned).\n"
            f"- 'key_difference': What makes the current case different? (Crucial for decision making)\n"
        )

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.0  # Zero temperature for strict logic
            )

            return json.loads(response.choices[0].message.content)

        except json.JSONDecodeError:
            print("   [CaseAgent] LLM returned invalid JSON.")
            return {
                "is_relevant": False,
                "similarity_explanation": "Model failed to generate valid JSON.",
                "historical_answer": "Error",
                "key_difference": "Error"
            }
        except Exception as e:
            print(f"   [CaseAgent] LLM Parse Error: {e}")
            return {
                "is_relevant": False,
                "similarity_explanation": f"LLM Error: {str(e)}",
                "historical_answer": "Error",
                "key_difference": "Error"
            }